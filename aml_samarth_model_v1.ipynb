{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import warnings\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data_for_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train, df_test):\n",
    "    \"\"\"\n",
    "    normalizing continuous\n",
    "    adding features\n",
    "    normalizing continuous variables\n",
    "    \"\"\"\n",
    "    df_train[['pid','reading_count']] = df_train['key'].str.split('-', expand=True)\n",
    "    df_train = df_train.drop('pid', axis=1)\n",
    "    df_train['reading_count'] = df_train['reading_count'].astype(int)\n",
    "    \n",
    "    df_test[['pid','reading_count']] = df_test['key'].str.split('-', expand=True)\n",
    "    df_test = df_test.drop('pid', axis=1)\n",
    "    df_test['reading_count'] = df_test['reading_count'].astype(int)\n",
    "       \n",
    "    #normalize\n",
    "    cols = ['xx1','xx2','xx3','xx4','xx5'] \n",
    "    for col in cols:\n",
    "        df_test[col] = (df_test[col] - df_train[col].mean())/df_train[col].std()\n",
    "        df_train[col] = (df_train[col] - df_train[col].mean())/df_train[col].std()\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocessing(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MAP = train.drop(['y_mean_HR','key'], axis = 1)\n",
    "train_HR = train.drop(['y_mean_MAP','key'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = range(int(train.shape[0]*80/100), train.shape[0])\n",
    "train_idx = range(int(train.shape[0]*80/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_MAP = train_MAP.loc[valid_idx,:]\n",
    "train_MAP = train_MAP.loc[train_idx,:]\n",
    "valid_HR = train_HR.loc[valid_idx,:]\n",
    "train_HR = train_HR.loc[train_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb on MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7242357640461901"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.1, max_depth=7, n_estimators=50)\n",
    "model.fit(train_MAP.drop('y_mean_MAP', axis=1), train_MAP['y_mean_MAP'])\n",
    "model.score(valid_MAP.drop('y_mean_MAP', axis=1), valid_MAP['y_mean_MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6977873200279159"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GradientBoostingRegressor(learning_rate=0.3, max_depth=7, n_estimators=50)\n",
    "model1.fit(train_MAP.drop('y_mean_MAP', axis=1), train_MAP['y_mean_MAP'])\n",
    "model1.score(valid_MAP.drop('y_mean_MAP', axis=1), valid_MAP['y_mean_MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706162649819891"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GradientBoostingRegressor(learning_rate=0.1, max_depth=10, n_estimators=50)\n",
    "model2.fit(train_MAP.drop('y_mean_MAP', axis=1), train_MAP['y_mean_MAP'])\n",
    "model2.score(valid_MAP.drop('y_mean_MAP', axis=1), valid_MAP['y_mean_MAP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rf on MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7025599503610953"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=10,\n",
    "                                 max_features='sqrt', random_state=42, verbose=True)\n",
    "model_rf.fit(train_MAP.drop('y_mean_MAP', axis=1), train_MAP['y_mean_MAP'])\n",
    "model_rf.score(valid_MAP.drop('y_mean_MAP', axis=1), valid_MAP['y_mean_MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6958036260422567"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_1 = RandomForestRegressor(n_estimators=500, min_samples_leaf=5,\n",
    "                                 max_features='sqrt', random_state=42, verbose=True, n_jobs=-1)\n",
    "model_rf_1.fit(train_MAP.drop('y_mean_MAP', axis=1), train_MAP['y_mean_MAP'])\n",
    "model_rf_1.score(valid_MAP.drop('y_mean_MAP', axis=1), valid_MAP['y_mean_MAP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST model for MAP is xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_predictions = model.predict(test.drop('key', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb on HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922465360829545"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR = GradientBoostingRegressor(learning_rate=0.1, max_depth=7, n_estimators=50)\n",
    "model_HR.fit(train_HR.drop('y_mean_HR', axis=1), train_HR['y_mean_HR'])\n",
    "model_HR.score(valid_HR.drop('y_mean_HR', axis=1), valid_HR['y_mean_HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821506145872234"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_HR = GradientBoostingRegressor(learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "model1_HR.fit(train_HR.drop('y_mean_HR', axis=1), train_HR['y_mean_HR'])\n",
    "model1_HR.score(valid_HR.drop('y_mean_HR', axis=1), valid_HR['y_mean_HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8706712503905317"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_HR = GradientBoostingRegressor(learning_rate=0.1, max_depth=7, n_estimators=100)\n",
    "model2_HR.fit(train_HR.drop('y_mean_HR', axis=1), train_HR['y_mean_HR'])\n",
    "model2_HR.score(valid_HR.drop('y_mean_HR', axis=1), valid_HR['y_mean_HR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rf on HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8441189773874381"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR_rf = RandomForestRegressor(n_estimators=500, min_samples_leaf=5,\n",
    "                                    max_features='sqrt', random_state=42, verbose=True, n_jobs=-1)\n",
    "model_rf_1.fit(train_HR.drop('y_mean_HR', axis=1), train_HR['y_mean_HR'])\n",
    "model_rf_1.score(valid_HR.drop('y_mean_HR', axis=1), valid_HR['y_mean_HR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model for HR is xbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_predictions = model_HR.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y_mean_MAP'] = MAP_predictions\n",
    "test['y_mean_HR'] = HR_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "toSubmit = test[['key','y_mean_MAP','y_mean_HR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "toSubmit = toSubmit.groupby('key').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "toSubmit.to_csv(\"no_one_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
